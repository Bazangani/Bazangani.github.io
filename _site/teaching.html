

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Computer vision</title>
    
    
    <meta name="author" content="Sarah Bazangani">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/kbroman.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->
    <link rel="SHORTCUT ICON" href="/me.ico"/>

    <!-- atom & rss feed -->
    <link href="nil" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="nil" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">

  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">Sarah Bazangani</a>
          <ul class="nav">
             
              <li><a href="/pubs.html">Publications</a></li>
			  <li><a href="/Computer Vision Tutorials.html">Computer Vision Tutorials</a></li>

              <li><a href="/tutorials.html">Data science Tutorials</a></li>
			  <li><a href="/projects/projects.html">Projects</a></li>
			  
              
              <!-- <li><a href="/software.html">Software</a></li> -->
             
          </ul>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        

<div class="page-header">
  <h2>Computer vision </h2>
</div>

<div class="row-fluid">
  <div class="span12">
    <h4 id="rccn--featurs-matters-">RCCN ; Featurs Matters !</h4>

<ul>
  <li><a href="https://www">Paper</a></li>
</ul>

<p>Detecting objects is a still a challenge in the field of computer vision, where the task is to teach machines to identify and locate different objects within images or videos.</p>

<p>Object detection needs to handle two objectives: identifying the presence of an object within an image or video and precisely determining the object’s position within the frame.</p>

<p>Within this post, I provide a summary of Ross Girshick’s paper, “Rich feature hierarchies for precise object detection and semantic segmentation” [1].</p>

<p>Before [1], one of the earliest approach employed for object detection is sliding windows. It systematically scan an image with a small rectangular window or “patch,” moving it across the image’s entire surface. This method aims to identify and localize objects of interest within the image by analyzing the content within each window as it shown in Figure bellow:</p>

<p>It’s important to highlight that feature extraction must happen within each patch at every stage. Subsequently, the network employs these extracted features to determine the presence of an object in the image.</p>

<p>The sliding window approach has several drawbacks, including computational inefficiency due to the analysis of overlapping windows, potential redundancy in processing similar information, dependence on fixed window sizes that may not adapt to varying object sizes, challenges in managing scale variability, limitations in capturing contextual information, difficulties in detecting closely spaced objects.</p>

<p>So in [1], they addressed these issues with “recognition using regions”. This paradigm analyses different regions or patches of the image rather than the entire image.</p>

<p>RCNN (Region-based Convolutional Neural Network) is an object detection approach that identifies potential object regions in an image. It extracts features from these regions using a CNN, allowing more efficient and accurate object classification and localization than analyzing the entire image.</p>

<p>So the model take an image as the input and extract 200K region proposals (frames). For every region proposal, features are extracted using a Convolutional Neural Network (CNN). This involves passing the region through the CNN, which transforms the visual information into representative features.</p>

<p>The extracted features from each region proposal are then used to classify the region into different object classes. Class-specific linear Support Vector Machines (SVMs) are employed for this task. Each class has its own SVM trained to distinguish that class from others based on the extracted features.</p>

<p>As mentioned, RCNN consists of three distinct parts. In the upcoming section, we will provide a detailed exploration of each step.</p>

<h2 id="region-proposals">Region proposals:</h2>

<p>In the RCNN framework, the Selective Search algorithm generates diverse region proposals within an image.</p>

<p>Selective Search is an algorithm for object recognition proposed in 2012 by [2]. The algorithm operates by combining smaller image segments into larger regions based on similarity in colour, texture, or other visual attributes. This process helps group parts of the image that share common characteristics, which can indicate objects. The algorithm then progressively merges these regions to generate a hierarchy of region proposals at multiple scales. It starts by treating each pixel or small region as an individual segment. Then, it progressively integrates these segments into larger and more complex regions based on similarity criteria. The merging continues until a set of candidate region proposals at different scales and levels of detail is obtained.</p>

<p>The method is detailed in Algorithm 1 as follows:</p>

<p>So First the algorithm take an input image and define the initial regions. In the next step, it compute the similarity between all neighbouring regions s(ri , rj). Two regions that share the highest similarity are combined, similarities are computed again between the resultant region and its adjacent counterparts.</p>

<p>The hierarchical grouping algorithm applied to a variety of colour spaces with
a range of invariance properties such as RGB, grey scale, and HSV.</p>

<p>For example, for every region, we generate one-dimensional color histograms for each color channel using 25 bins. Consequently, this results in a color histogram Ci = {ci1, …, cni} for each region ri, where the dimensionality is n = 75 when considering three color channels.</p>

<p>The measurement of similarity is accomplished through histogram intersection:</p>

<p>–</p>
<h1 id="refrences">Refrences</h1>

<p>[1] Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 580-587).</p>

<p>[2] Uijlings, J. R., Van De Sande, K. E., Gevers, T., &amp; Smeulders, A. W. (2013). Selective search for object recognition. International journal of computer vision, 104, 154-171.</p>

  </div>
</div>


      </div>

      <hr>

    </div>

    
  </body>
</html>

